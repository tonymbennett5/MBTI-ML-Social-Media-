{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import re \n",
    "import nltk "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing csv \n",
    "df_clean2 = pd.read_csv(r\"C:\\Users\\tonym\\Documents\\Flatiron\\phase_5\\capstone\\MBTI-ML-Social-Media-\\data\\df_clean2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>Extrovert</th>\n",
       "      <th>Sensing</th>\n",
       "      <th>Thinking</th>\n",
       "      <th>Judging</th>\n",
       "      <th>posts</th>\n",
       "      <th>cleaned posts</th>\n",
       "      <th>compound_sentiment</th>\n",
       "      <th>positive_sent</th>\n",
       "      <th>negative_sent</th>\n",
       "      <th>...</th>\n",
       "      <th>ADV_avg</th>\n",
       "      <th>CONJ_avg</th>\n",
       "      <th>DET_avg</th>\n",
       "      <th>NOUN_avg</th>\n",
       "      <th>NUM_avg</th>\n",
       "      <th>PRT_avg</th>\n",
       "      <th>PRON_avg</th>\n",
       "      <th>VERB_avg</th>\n",
       "      <th>._avg</th>\n",
       "      <th>X_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>'http://www.youtube.com/watch?v=qsXHcwe3krw|||...</td>\n",
       "      <td>and  moments    sportscenter not top ten p...</td>\n",
       "      <td>0.9826</td>\n",
       "      <td>0.178</td>\n",
       "      <td>0.113</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>'I'm finding the lack of me in these posts ver...</td>\n",
       "      <td>finding the lack    these  very alarming  s...</td>\n",
       "      <td>0.9984</td>\n",
       "      <td>0.206</td>\n",
       "      <td>0.106</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INTP</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>'Good one  _____   https://www.youtube.com/wat...</td>\n",
       "      <td>good one            course   which  say  know...</td>\n",
       "      <td>0.9985</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.098</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>'Dear INTP,   I enjoyed our conversation the o...</td>\n",
       "      <td>dear      enjoyed our conversation the other ...</td>\n",
       "      <td>0.9985</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.067</td>\n",
       "      <td>...</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTJ</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>'You're fired.|||That's another silly misconce...</td>\n",
       "      <td>you  fired  that  another silly misconception...</td>\n",
       "      <td>0.9917</td>\n",
       "      <td>0.207</td>\n",
       "      <td>0.163</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 115 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   type  Extrovert  Sensing  Thinking  Judging  \\\n",
       "0  INFJ          0        0         0        1   \n",
       "1  ENTP          1        0         1        0   \n",
       "2  INTP          0        0         1        0   \n",
       "3  INTJ          0        0         1        1   \n",
       "4  ENTJ          1        0         1        1   \n",
       "\n",
       "                                               posts  \\\n",
       "0  'http://www.youtube.com/watch?v=qsXHcwe3krw|||...   \n",
       "1  'I'm finding the lack of me in these posts ver...   \n",
       "2  'Good one  _____   https://www.youtube.com/wat...   \n",
       "3  'Dear INTP,   I enjoyed our conversation the o...   \n",
       "4  'You're fired.|||That's another silly misconce...   \n",
       "\n",
       "                                       cleaned posts  compound_sentiment  \\\n",
       "0      and  moments    sportscenter not top ten p...              0.9826   \n",
       "1     finding the lack    these  very alarming  s...              0.9984   \n",
       "2   good one            course   which  say  know...              0.9985   \n",
       "3   dear      enjoyed our conversation the other ...              0.9985   \n",
       "4   you  fired  that  another silly misconception...              0.9917   \n",
       "\n",
       "   positive_sent  negative_sent  ...  ADV_avg CONJ_avg DET_avg  NOUN_avg  \\\n",
       "0          0.178          0.113  ...      1.0      2.0     1.0       4.0   \n",
       "1          0.206          0.106  ...      2.0      4.0     2.0       6.0   \n",
       "2          0.224          0.098  ...      2.0      1.0     1.0       4.0   \n",
       "3          0.176          0.067  ...      1.5      3.0     2.0       5.0   \n",
       "4          0.207          0.163  ...      2.0      2.0     2.0       5.0   \n",
       "\n",
       "   NUM_avg  PRT_avg  PRON_avg  VERB_avg  ._avg  X_avg  \n",
       "0      0.0      0.0       1.0       2.0    2.5    0.0  \n",
       "1      0.0      0.0       4.0       6.0    4.0    0.0  \n",
       "2      0.0      0.0       2.0       4.0    3.0    0.0  \n",
       "3      0.0      0.0       3.0       5.0    3.0    0.0  \n",
       "4      0.0      0.0       3.0       5.0    3.0    0.0  \n",
       "\n",
       "[5 rows x 115 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8675, 115)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counting\n",
    "- question marks , exclamation points\n",
    "- Colons\n",
    "- Emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique_words(s):\n",
    "    unique = set(s.split(\" \"))\n",
    "    return len(unique) / 50\n",
    "\n",
    "def emojis(post):\n",
    "    emoji_count = 0\n",
    "    words = post.split()\n",
    "    for e in words:\n",
    "        if \"http\" not in e:\n",
    "            if e.count(\":\") == 2:\n",
    "                emoji_count += 1\n",
    "    return emoji_count / 50\n",
    "\n",
    "def colons(post):\n",
    "    colon_count = 0\n",
    "    words = post.split()\n",
    "    for e in words:\n",
    "        if \"http\" not in e:\n",
    "            colon_count += e.count (\":\")\n",
    "    return colon_count / 50        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean2['ques marks'] = df_clean2['posts'].apply(lambda s: s.count(\"?\") / 50)\n",
    "df_clean2['exc points'] = df_clean2['posts'].apply(lambda s: s.count(\"?\") / 50)\n",
    "df_clean2['colons'] = df_clean2['posts'].apply(colons)\n",
    "df_clean2['emojis'] = df_clean2['posts'].apply(emojis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#word count \n",
    "df_clean2[\"word_counts\"] = df_clean2[\"posts\"].apply(lambda s: (s.count(\" \") + 1) / 50)\n",
    "df_clean2[\"unique_words\"] = df_clean2[\"posts\"].apply(unique_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#upper case count\n",
    "df_clean2[\"upper_case\"] = df_clean2[\"posts\"].apply(lambda x: len([x for x in x.split() if x.isupper()]) / 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#link count \n",
    "df_clean2[\"link_counts\"] = df_clean2[\"posts\"].apply(lambda s: s.count(\"http\") / 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ellipses count \n",
    "ellipses_count = [len(re.findall(r\"\\.\\.\\.\\ \", posts)) / 50 for posts in df_clean2[\"posts\"]]\n",
    "df_clean2[\"ellipses_count\"] = ellipses_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#images count\n",
    "df_clean2[\"image_count\"] = [len(re.findall(r\"(\\.jpg)|(\\.jpeg)|(\\.gif)|(\\.png)\", post)) / 50\n",
    "    for post in df_clean2[\"posts\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#word stats \n",
    "df_clean2[\"post_var\"] = df_clean2[\"posts\"].apply(lambda x: np.var([len(post.split()) for post in x.split(\"|||\")])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean2[\"avg_word_count\"] = df_clean2[\"word_counts\"].apply(lambda s: s / 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>Extrovert</th>\n",
       "      <th>Sensing</th>\n",
       "      <th>Thinking</th>\n",
       "      <th>Judging</th>\n",
       "      <th>posts</th>\n",
       "      <th>cleaned posts</th>\n",
       "      <th>compound_sentiment</th>\n",
       "      <th>positive_sent</th>\n",
       "      <th>negative_sent</th>\n",
       "      <th>...</th>\n",
       "      <th>colons</th>\n",
       "      <th>emojis</th>\n",
       "      <th>word_counts</th>\n",
       "      <th>unique_words</th>\n",
       "      <th>upper_case</th>\n",
       "      <th>link_counts</th>\n",
       "      <th>ellipses_count</th>\n",
       "      <th>image_count</th>\n",
       "      <th>post_var</th>\n",
       "      <th>avg_word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>'http://www.youtube.com/watch?v=qsXHcwe3krw|||...</td>\n",
       "      <td>and  moments    sportscenter not top ten p...</td>\n",
       "      <td>0.9826</td>\n",
       "      <td>0.178</td>\n",
       "      <td>0.113</td>\n",
       "      <td>...</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.04</td>\n",
       "      <td>11.56</td>\n",
       "      <td>7.52</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>135.29</td>\n",
       "      <td>0.2312</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 127 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   type  Extrovert  Sensing  Thinking  Judging  \\\n",
       "0  INFJ          0        0         0        1   \n",
       "\n",
       "                                               posts  \\\n",
       "0  'http://www.youtube.com/watch?v=qsXHcwe3krw|||...   \n",
       "\n",
       "                                       cleaned posts  compound_sentiment  \\\n",
       "0      and  moments    sportscenter not top ten p...              0.9826   \n",
       "\n",
       "   positive_sent  negative_sent  ...  colons emojis word_counts  unique_words  \\\n",
       "0          0.178          0.113  ...    0.14   0.04       11.56          7.52   \n",
       "\n",
       "   upper_case  link_counts  ellipses_count  image_count  post_var  \\\n",
       "0        0.26         0.48            0.14         0.14    135.29   \n",
       "\n",
       "   avg_word_count  \n",
       "0          0.2312  \n",
       "\n",
       "[1 rows x 127 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean2.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean2.to_csv(r\"C:\\Users\\tonym\\Documents\\Flatiron\\phase_5\\capstone\\MBTI-ML-Social-Media-\\data\\df_clean3.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
